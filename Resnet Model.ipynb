{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0qyQSoK5a2q3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, Concatenate, Input, Dropout, UpSampling2D, MaxPooling2D, Add\n",
        "from sklearn.utils import shuffle\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ------------------------ Load Dataset ------------------------\n",
        "def load_patches(folder, img_size=(512, 512)):\n",
        "    images = []\n",
        "    filenames = sorted(os.listdir(folder))  # Ensure patches are loaded in order\n",
        "    for filename in filenames:\n",
        "        img = cv2.imread(os.path.join(folder, filename))\n",
        "        if img is not None:\n",
        "            img = cv2.resize(img, img_size)\n",
        "            img = img.astype(np.float32) / 255.0  # Normalize\n",
        "            images.append(img)\n",
        "    return np.array(images)\n",
        "\n",
        "# Load Training Data (Raw Images)\n",
        "X_mars = load_patches(\"Patches_mars\")\n",
        "X_crater = load_patches(\"Patches_crater\")\n",
        "X_train = np.concatenate([X_mars, X_crater], axis=0)\n",
        "\n",
        "# Load Ground Truth Data (Enhanced Images)\n",
        "Y_mars = load_patches(\"Patches_enhanced_mars\")\n",
        "Y_crater = load_patches(\"Patches_enhanced_crater\")\n",
        "Y_mars2 = load_patches(\"Patches_enhanced_mars2\")\n",
        "Y_train = np.concatenate([Y_mars, Y_crater, Y_mars2], axis=0)\n",
        "\n",
        "# Handle Data Imbalance (Ensure Equal Training & Validation Samples)\n",
        "# X_train, Y_train = shuffle(X_train, Y_train, random_state=42)  # Shuffle data\n",
        "\n",
        "# Print Dataset Shapes\n",
        "print(\"Training Data Shape:\", X_train.shape)\n",
        "print(\"Ground Truth Shape:\", Y_train.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ReflectionPadding2D(tf.keras.layers.Layer):\n",
        "    def __init__(self, padding=(1, 1), **kwargs):\n",
        "        super(ReflectionPadding2D, self).__init__(**kwargs)\n",
        "        self.padding = padding\n",
        "\n",
        "    def call(self, inputs):\n",
        "        pad_w, pad_h = self.padding\n",
        "        return tf.pad(inputs, [[0, 0], [pad_h, pad_h], [pad_w, pad_w], [0, 0]], mode='REFLECT')\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(ReflectionPadding2D, self).get_config()\n",
        "        config.update({'padding': self.padding})\n",
        "        return config\n",
        "\n",
        "def build_cnn_model():\n",
        "    inputs = Input(shape=(512, 512, 3))\n",
        "\n",
        "    # Convolutional Layers\n",
        "    x = ReflectionPadding2D((1, 1))(inputs)\n",
        "    x = Conv2D(64, (3, 3), padding=\"valid\")(inputs)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    # Residual Blocks (Adding multiple layers for enhancement)\n",
        "    for _ in range(8):\n",
        "        res = ReflectionPadding2D((1, 1))(x)\n",
        "        res = Conv2D(64, (3, 3), padding=\"valid\")(x)\n",
        "        res = BatchNormalization()(res)\n",
        "        res = Activation(\"relu\")(res)\n",
        "        res = ReflectionPadding2D((1, 1))(res)\n",
        "        res = Conv2D(64, (3, 3), padding=\"valid\")(res)\n",
        "        res = BatchNormalization()(res)\n",
        "        x = Add()([x, res])  # Skip Connection\n",
        "\n",
        "    # Output Layer (Restores Enhanced Image)\n",
        "    x = ReflectionPadding2D((1, 1))(x)\n",
        "    x = Conv2D(3, (3, 3), padding=\"valid\", activation=\"sigmoid\")(x)\n",
        "\n",
        "    model = Model(inputs, x)\n",
        "    return model\n",
        "\n",
        "model = build_deep_unet()\n",
        "model.compile(optimizer=Adam(learning_rate=1e-4), loss='mean_squared_error', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "GD4pE24PbFe_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------ Train CNN Model ------------------------\n",
        "history = model.fit(\n",
        "    X_train, Y_train,\n",
        "    validation_split=0.1,\n",
        "    epochs=50,\n",
        "    batch_size=6,\n",
        "    shuffle=True\n",
        ")"
      ],
      "metadata": {
        "id": "yGQGdIDyduLD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the Model\n",
        "model.save(\"mars_enhancement_resnet.pth\")\n",
        "print(\"model saved\")"
      ],
      "metadata": {
        "id": "FRuSaU3I4x6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------ Plot Training History ------------------------\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Get training history from the model\n",
        "history_dict = history.history\n",
        "\n",
        "# Plot Loss (Training & Validation)\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history_dict['loss'], label='Training Loss')\n",
        "plt.plot(history_dict['val_loss'], label='Validation Loss')\n",
        "plt.title('Loss Over Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss (MSE)')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# Plot MAE (Training & Validation)\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history_dict['mae'], label='Training MAE')\n",
        "plt.plot(history_dict['val_mae'], label='Validation MAE')\n",
        "plt.title('Mean Absolute Error Over Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('MAE')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "w4VRljWF44ya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def enhance_patches(input_folder, output_folder, model):\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    for filename in sorted(os.listdir(input_folder)):\n",
        "        img_path = os.path.join(input_folder, filename)\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is None:\n",
        "          print(f\"Skipping invalid image: {filename}\")\n",
        "          continue\n",
        "        img = cv2.resize(img, (512, 512)).astype(np.float32) / 255.0\n",
        "        img = np.expand_dims(img, axis=0)  # Add batch dimension\n",
        "\n",
        "        enhanced_img = model.predict(img)[0]  # Remove batch dimension\n",
        "        enhanced_img = (enhanced_img * 255).astype(np.uint8)\n",
        "\n",
        "        cv2.imwrite(os.path.join(output_folder, filename), enhanced_img)\n",
        "\n",
        "# Enhance Training Images\n",
        "enhance_patches(\"Patches_mars\", \"Enhanced_mars_resnet\", model)\n",
        "enhance_patches(\"Patches_crater\", \"Enhanced_crater_resnet\", model)"
      ],
      "metadata": {
        "id": "2Va4x8Rg48u7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------ Stitch Patches Back ------------------------\n",
        "def stitch_patches(patch_folder, output_image_path, grid_size=(4, 4), patch_size=(512, 512)):\n",
        "    stitched_image = np.zeros((patch_size[0] * grid_size[0], patch_size[1] * grid_size[1], 3), dtype=np.uint8)\n",
        "\n",
        "    patches = sorted([f for f in os.listdir(patch_folder) if f.lower().endswith(('.png'. '.jpg', '.jpeg'))])  # Ensure correct order\n",
        "    expected_patches = grid_size[0] * grid_size[1]\n",
        "\n",
        "    if len(patches) < expected_patches:\n",
        "        raise ValueError(f\"Expected '{patch_folder}' patches, but found {len(patches)} in {expected_patches}\")\n",
        "    idx = 0\n",
        "\n",
        "    for i in range(grid_size[0]):\n",
        "        for j in range(grid_size[1]):\n",
        "            patch = cv2.imread(os.path.join(patch_folder, patches[idx]))\n",
        "\n",
        "            if patch is None:\n",
        "                raise FileNotFoundError(f\"Cannot read patch: {patch}\")\n",
        "            stitched_image[i * patch_size[0]: (i + 1) * patch_size[0], j * patch_size[1]: (j + 1) * patch_size[1]] = patch\n",
        "            idx += 1\n",
        "\n",
        "    cv2.imwrite(output_image_path, stitched_image)\n",
        "\n",
        "# Stitch Enhanced Images\n",
        "stitch_patches(\"Enhanced_mars_resnet\", \"resnet_mars.png\")\n",
        "stitch_patches(\"Enhanced_crater_resnet\", \"resnet_crater.png\")\n"
      ],
      "metadata": {
        "id": "pVDIHnlw5Cgo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --------- Replace with your actual image filenames ---------\n",
        "image_paths = [\n",
        "    \"mars.jpg\",  # or .jpg or whatever your extensions are\n",
        "    \"Enhanced_mars.jpg\",\n",
        "    \"unet_mars.png\",\n",
        "    \"resnet_mars.png\",\n",
        "    \"crater.jpg\",\n",
        "    \"Enhanced_crater.jpg\",\n",
        "    \"unet_crater.png\",\n",
        "    \"resnet_crater.png\"\n",
        "]\n",
        "\n",
        "# --------- Read and convert images from BGR to RGB ---------\n",
        "images = []\n",
        "for path in image_paths:\n",
        "    img = cv2.imread(path)\n",
        "    if img is not None:\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert to RGB for matplotlib\n",
        "        images.append(img)\n",
        "    else:\n",
        "        print(f\"Warning: Couldn't read image: {path}\")\n",
        "        images.append(None)\n",
        "\n",
        "# --------- Plot images: 2 rows, 3 images per row ---------\n",
        "fig, axs = plt.subplots(2, 4, figsize=(15, 10))  # 2 rows x 3 columns\n",
        "\n",
        "for i, ax in enumerate(axs.flat):\n",
        "    if images[i] is not None:\n",
        "        ax.imshow(images[i])\n",
        "        ax.set_title(f\"Image {i+1}\")\n",
        "    else:\n",
        "        ax.set_title(\"Missing Image\")\n",
        "    ax.axis(\"off\")  # Hide axis\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "HYNO0-Fu49Nn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "def split_image_smooth(image_path, output_folder, patch_size=(512, 512)):\n",
        "    \"\"\"\n",
        "    Split image into clean patches without borders/lines.\n",
        "    Saves patches in PNG format to avoid compression artifacts.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is None:\n",
        "        raise ValueError(\"Image not found or invalid format\")\n",
        "\n",
        "    h, w, _ = image.shape\n",
        "    patch_h, patch_w = patch_size\n",
        "\n",
        "    count = 0\n",
        "    for i in range(0, h, patch_h):\n",
        "        for j in range(0, w, patch_w):\n",
        "            patch = image[i:i+patch_h, j:j+patch_w]\n",
        "            # Ensure patch is full size\n",
        "            if patch.shape[0] != patch_h or patch.shape[1] != patch_w:\n",
        "                continue\n",
        "            patch_path = os.path.join(output_folder, f\"patch_{i//patch_h}_{j//patch_w}.png\")\n",
        "            cv2.imwrite(patch_path, patch)  # Use PNG only (no artifacts)\n",
        "            count += 1\n",
        "\n",
        "    print(f\"✅ Saved {count} clean patches to '{output_folder}'\")\n"
      ],
      "metadata": {
        "id": "Dq8xV_pF49R7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def enhance_patches_with_model(patch_folder, output_folder, model_path):\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    # Load model\n",
        "    model = tf.keras.models.load_model(model_path)\n",
        "    print(\"📦 Loaded model:\", model_path)\n",
        "\n",
        "    patches = sorted([f for f in os.listdir(patch_folder) if f.endswith('.png')])\n",
        "    for filename in patches:\n",
        "        path = os.path.join(patch_folder, filename)\n",
        "        image = cv2.imread(path)\n",
        "        if image is None:\n",
        "            print(f\"⚠️ Skipping: {filename} (invalid image)\")\n",
        "            continue\n",
        "\n",
        "        # Normalize and reshape for model\n",
        "        inp = image.astype(np.float32) / 255.0\n",
        "        inp = np.expand_dims(inp, axis=0)\n",
        "\n",
        "        # Predict\n",
        "        pred = model.predict(inp)[0]\n",
        "        pred = np.clip(pred * 255.0, 0, 255).astype(np.uint8)\n",
        "\n",
        "        # Save enhanced patch\n",
        "        out_path = os.path.join(output_folder, filename)\n",
        "        cv2.imwrite(out_path, pred)\n",
        "\n",
        "    print(f\"✨ Enhanced patches saved to '{output_folder}'\")"
      ],
      "metadata": {
        "id": "kBst8Kmg49Wn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gaussian_weight_mask(patch_size):\n",
        "    \"\"\"\n",
        "    Generates a 2D Gaussian weight mask for smooth blending of patches.\n",
        "    \"\"\"\n",
        "    h, w = patch_size\n",
        "    y = np.linspace(-1, 1, h)\n",
        "    x = np.linspace(-1, 1, w)\n",
        "    xx, yy = np.meshgrid(x, y)\n",
        "    d = np.sqrt(xx**2 + yy**2)\n",
        "    sigma = 0.5\n",
        "    gauss = np.exp(-((d**2) / (2.0 * sigma ** 2)))\n",
        "    gauss -= gauss.min()\n",
        "    gauss /= gauss.max()\n",
        "    return gauss[..., np.newaxis]  # Add channel dimension\n",
        "\n",
        "\n",
        "def final_smooth_stitch(patch_folder, output_path, grid_size=(4, 4), patch_size=(512, 512)):\n",
        "    H, W = patch_size\n",
        "    stitched_h = H * grid_size[0]\n",
        "    stitched_w = W * grid_size[1]\n",
        "\n",
        "    stitched = np.zeros((stitched_h, stitched_w, 3), dtype=np.float32)\n",
        "    weight_map = np.zeros((stitched_h, stitched_w, 3), dtype=np.float32)\n",
        "\n",
        "    patches = sorted([f for f in os.listdir(patch_folder) if f.endswith('.png')])\n",
        "    if len(patches) != grid_size[0] * grid_size[1]:\n",
        "        raise ValueError(f\"Expected {grid_size[0]*grid_size[1]} patches, found {len(patches)}\")\n",
        "\n",
        "    print(f\"Found {len(patches)} patches in {patch_folder}\")\n",
        "\n",
        "    weight_mask = gaussian_weight_mask(patch_size)\n",
        "\n",
        "    idx = 0\n",
        "    for i in range(grid_size[0]):\n",
        "        for j in range(grid_size[1]):\n",
        "            if idx >= len(patches):\n",
        "                continue\n",
        "            patch_path = os.path.join(patch_folder, patches[idx])\n",
        "            patch = cv2.imread(patch_path)\n",
        "            if patch is None:\n",
        "                raise ValueError(f\"❌ Cannot read patch: {patch_path}\")\n",
        "            patch = patch.astype(np.float32)\n",
        "\n",
        "            y1 = i * patch_size[0]\n",
        "            x1 = j * patch_size[1]\n",
        "\n",
        "            stitched[y1:y1+H, x1:x1+W] += patch * weight_mask\n",
        "            weight_map[y1:y1+H, x1:x1+W] += weight_mask\n",
        "            idx += 1\n",
        "\n",
        "    weight_map[weight_map == 0] = 1\n",
        "    final_img = stitched / weight_map\n",
        "    final_img = np.clip(final_img, 0, 255).astype(np.uint8)\n",
        "\n",
        "    cv2.imwrite(output_path, final_img)\n",
        "    print(f\"✅ Final stitched image saved to {output_path}\")\n",
        "\n",
        "    # Show result\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    plt.imshow(cv2.cvtColor(final_img, cv2.COLOR_BGR2RGB))\n",
        "    plt.title(\"Final Smooth Stitched Image\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "7gLDae8N5gAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Split\n",
        "split_image_smooth(\"mars13.jpg\", \"Patches_mars13\", patch_size=(512, 512))\n",
        "\n",
        "# Step 2: Enhance using your trained model\n",
        "enhance_patches_with_model(\"Patches_mars13\", \"Enhanced_mars13_resnet\", \"mars_enhancement_resnet.pth\")\n",
        "\n",
        "# Step 3: Stitch result\n",
        "final_smooth_stitch(\"Enhanced_mars13_resnet\", \"resnet_mars13.png\", grid_size=(4, 4), patch_size=(512, 512))\n"
      ],
      "metadata": {
        "id": "jkkpRCko5ljz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --------- Replace with your actual image filenames ---------\n",
        "image_paths = [\n",
        "    \"mars13.jpg\",  # or .jpg or whatever your extensions are\n",
        "    \"Enhanced_mars13.jpg\",\n",
        "    \"unet_mars13.png\",\n",
        "    \"resnet_mars13.jpg\"\n",
        "]\n",
        "\n",
        "# --------- Read and convert images from BGR to RGB ---------\n",
        "images = []\n",
        "for path in image_paths:\n",
        "    img = cv2.imread(path)\n",
        "    if img is not None:\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert to RGB for matplotlib\n",
        "        images.append(img)\n",
        "    else:\n",
        "        print(f\"Warning: Couldn't read image: {path}\")\n",
        "        images.append(None)\n",
        "\n",
        "# --------- Plot images: 2 rows, 3 images per row ---------\n",
        "fig, axs = plt.subplots(1, 3, figsize=(15, 10))  # 2 rows x 3 columns\n",
        "\n",
        "for i, ax in enumerate(axs.flat):\n",
        "    if images[i] is not None:\n",
        "        ax.imshow(images[i])\n",
        "        ax.set_title(f\"Image {i+1}\")\n",
        "    else:\n",
        "        ax.set_title(\"Missing Image\")\n",
        "    ax.axis(\"off\")  # Hide axis\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KdT86fO96OCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from skimage import io, img_as_ubyte, img_as_float\n",
        "from skimage.measure import shannon_entropy\n",
        "from skimage.restoration import estimate_sigma\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "from skimage import color\n",
        "import os\n"
      ],
      "metadata": {
        "id": "OiWWJmIZ6w98"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage import exposure\n",
        "from skimage.util import img_as_ubyte\n",
        "from skimage.metrics import mean_squared_error\n",
        "from skimage import img_as_float\n",
        "from skimage.color import rgb2gray\n",
        "from skimage.restoration import estimate_sigma\n",
        "from skimage import util\n",
        "from skimage.measure import shannon_entropy\n",
        "\n",
        "def compute_mscn_coefficients(img, kernel_size=7, sigma=7/6):\n",
        "    img = img.astype(np.float32)\n",
        "    mu = cv2.GaussianBlur(img, (kernel_size, kernel_size), sigma)\n",
        "    mu_sq = mu * mu\n",
        "    sigma = cv2.GaussianBlur(img * img, (kernel_size, kernel_size), sigma)\n",
        "    sigma = np.sqrt(np.abs(sigma - mu_sq))\n",
        "    mscn = (img - mu) / (sigma + 1e-5)\n",
        "    return mscn\n",
        "\n",
        "def brisque_numpy(img):\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "    mscn = compute_mscn_coefficients(gray)\n",
        "    mean_mscn = np.mean(mscn)\n",
        "    std_mscn = np.std(mscn)\n",
        "    return np.abs(mean_mscn) + std_mscn\n",
        "\n",
        "def niqe_numpy(img):\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "    mscn = compute_mscn_coefficients(gray)\n",
        "    mean = np.mean(mscn)\n",
        "    var = np.var(mscn)\n",
        "    return np.sqrt(mean**2 + var)\n",
        "\n",
        "def piqe_numpy(img, block_size=32, threshold=10):\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "    h, w = gray.shape\n",
        "    distorted_blocks = 0\n",
        "    total_blocks = 0\n",
        "\n",
        "    for i in range(0, h, block_size):\n",
        "        for j in range(0, w, block_size):\n",
        "            block = gray[i:i+block_size, j:j+block_size]\n",
        "            if block.size == 0 or block.shape[0] != block_size or block.shape[1] != block_size:\n",
        "                continue\n",
        "            std_dev = np.std(block)\n",
        "            if std_dev < threshold:\n",
        "                distorted_blocks += 1\n",
        "            total_blocks += 1\n",
        "\n",
        "    piqe_score = (distorted_blocks / total_blocks) * 100\n",
        "    return piqe_score\n",
        "\n",
        "\n",
        "# Entropy\n",
        "def compute_entropy(image):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
        "    return shannon_entropy(gray)\n",
        "\n",
        "# SNR (no-reference estimation)\n",
        "def compute_snr(image):\n",
        "    image = img_as_float(rgb2gray(image))\n",
        "    mu = np.mean(image)\n",
        "    sigma = estimate_sigma(image, multichannel=False)\n",
        "    return 10 * np.log10(mu**2 / sigma**2)\n",
        "\n",
        "\n",
        "# HVS Sharpness\n",
        "def compute_hvs_sharpness(image):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
        "    laplacian = cv2.Laplacian(gray, cv2.CV_64F)\n",
        "    return np.var(laplacian)\n"
      ],
      "metadata": {
        "id": "2s67mK_I60mS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import pandas as pd\n",
        "\n",
        "# Replace with your actual image paths and titles\n",
        "image_paths = ['mars13.jpg', 'Enhanced_mars13.jpg', 'unet_mars13.png', 'resnet_mars13.png']\n",
        "image_titles = ['original', 'GT', 'unet', 'resnet']\n",
        "metrics = []\n",
        "\n",
        "for path in image_paths:\n",
        "    img = cv2.imread(path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Use the improved NumPy-based metric functions\n",
        "    brisque_score = brisque_numpy(img)\n",
        "    niqe_val = niqe_numpy(img)\n",
        "    piqe_val = piqe_numpy(img)\n",
        "\n",
        "    entropy_val = compute_entropy(img)\n",
        "    snr_val = compute_snr(img)\n",
        "    hvs_val = compute_hvs_sharpness(img)\n",
        "\n",
        "    metrics.append({\n",
        "        'BRISQUE ↓': round(brisque_score, 2),\n",
        "        'NIQE ↓': round(niqe_val, 2),\n",
        "        'PIQE ↓': round(piqe_val, 2),\n",
        "        'Entropy ↑': round(entropy_val, 2),\n",
        "        'SNR ↑': round(snr_val, 2),\n",
        "        'HVS Sharpness ↑': round(hvs_val, 2),\n",
        "    })\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame(metrics, index=image_titles)\n",
        "\n",
        "# Display the table\n",
        "print(\"📊 No-Reference Image Quality Metrics Comparison Table:\\n\")\n",
        "display(df.style.set_caption(\"Comparison of Image Quality Metrics\")\n",
        "        .set_table_styles([{'selector': 'caption',\n",
        "                            'props': [('color', 'black'),\n",
        "                                      ('font-size', '16px'),\n",
        "                                      ('text-align', 'center'),\n",
        "                                      ('font-weight', 'bold')]}])\n",
        "        .set_properties(**{'text-align': 'center'})\n",
        "        .highlight_min(axis=0, subset=['BRISQUE ↓', 'NIQE ↓', 'PIQE ↓'], color='lightgreen')\n",
        "        .highlight_max(axis=0, subset=['Entropy ↑', 'SNR ↑', 'HVS Sharpness ↑'], color='lightblue'))\n"
      ],
      "metadata": {
        "id": "QmXi-1vE63aK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define metric names and colors\n",
        "metric_names = ['BRISQUE ↓', 'Entropy ↑', 'SNR ↑', 'NIQE ↓', 'PIQE ↓', 'HVS Sharpness ↑']\n",
        "colors = ['tomato', 'gold', 'darkcyan', 'mediumorchid', 'darkorange', 'deepskyblue']\n",
        "\n",
        "fig, axs = plt.subplots(3, 2, figsize=(14, 14))\n",
        "fig.suptitle(\"📊 No-Reference Image Quality Metrics (Visual Comparison)\", fontsize=18, weight='bold', y=1.02)\n",
        "\n",
        "axs = axs.flatten()\n",
        "\n",
        "for i, metric in enumerate(metric_names):\n",
        "    values = df_metrics[metric].values\n",
        "    axs[i].bar(image_titles, values, color=colors[i], edgecolor='black')\n",
        "\n",
        "    axs[i].set_title(metric, fontsize=14, pad=10)\n",
        "\n",
        "    max_val = max(values)\n",
        "    padding = max_val * 0.01  # Add 15% padding above tallest bar\n",
        "    axs[i].set_ylim(0, max_val + padding)\n",
        "\n",
        "    # Put labels inside the bars if possible\n",
        "    for j, val in enumerate(values):\n",
        "        label_y = val + (padding * 0.1) if val < max_val + padding * 0.5 else val - (padding * 0.1)\n",
        "        ha = 'center'\n",
        "        va = 'bottom' if label_y < val else 'top'\n",
        "        axs[i].text(j, label_y, f\"{val:.2f}\", ha=ha, va=va, fontsize=10, color='black')\n",
        "\n",
        "    axs[i].set_ylabel(\"↑ Better\" if '↑' in metric else \"↓ Better\", fontsize=11)\n",
        "    axs[i].grid(True, linestyle='--', alpha=0.5)\n",
        "\n",
        "# Clean up extra axes if any\n",
        "for i in range(len(metric_names), len(axs)):\n",
        "    fig.delaxes(axs[i])\n",
        "\n",
        "plt.subplots_adjust(hspace=0.3, top=0.9)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "_kFTD4rE63f2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
